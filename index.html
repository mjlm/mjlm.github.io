<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Matthias Minderer</title>
  
  <meta name="author" content="Matthias Minderer">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Matthias Minderer</name>
              </p>
              <p>I am a Senior Research Scientist at <a href="https://deepmind.google/">Google DeepMind</a> in Z&uuml;rich, where I work on computer vision.
              </p>
              <p>
              	Before joining Google, I received a PhD from <a href="https://www.hms.harvard.edu/dms/neuroscience/">Harvard University</a>, working with <a href="http://harveylab.hms.harvard.edu/">Christopher Harvey</a>. My thesis focused on the representation of visual and action-related information in the mammalian cerebral cortex. Earlier, I studied neuroscience at <a href="https://ethz.ch/en.html">ETH Z&uuml;rich</a> and biochemistry at the <a href="https://www.cam.ac.uk/">University of Cambridge</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:m.minderer@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/cv_matthias_minderer_jun_2021.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=57BFBY0AAAAJ">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/matthias_minderer.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/matthias_minderer_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in visual representation learning, specifically how to impart abstract structure and inductive biases to the representations learned by deep neural network to make them more useful, interpretable, and robust.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	  <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publications</heading>
              <p>
                For a full list, see <a href="https://scholar.google.com/citations?hl=en&user=57BFBY0AAAAJ">Google Scholar</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
				<img src='images/owl_v2.png' width=100%>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2306.09683">
                <papertitle>OWL-ViT v2: Scaling Open-Vocabulary Object Detection</papertitle>
              </a>
              <br>
              <strong>Matthias Minderer</strong>, Alexey Gritsenko, Neil Houlsby
              <br>
              <em>preprint</em>, 2023
              <br>
              <p></p>
              <p>We scale open-vocabulary object detection through self-training on pseudo-labeled web image-text data.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
				<img src='images/text_cond_wiki_stillife_1.gif' width=100%>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2205.06230">
                <papertitle>OWL-ViT: Simple Open-Vocabulary Object Detection with Vision Transformers</papertitle>
              </a>
              <br>
              <strong>Matthias Minderer</strong>, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, Neil Houlsby
              <br>
              <em>ECCV</em>, 2022
              <br>
              <p></p>
              <p>We develop a simple transformer-based architecture and training recipe that achieves strong performance in open-vocabulary object detection.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
				<img src='images/revisiting_small.png' width=100%>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2106.07998">
                <papertitle>Revisiting the Calibration of Modern Neural Networks</papertitle>
              </a>
              <br>
              <strong>Matthias Minderer</strong>, Josip Djolonga, Rob Romijnders, Frances Hubis, Xiaohua Zhai, Neil Houlsby, Dustin Tran, Mario Lucic
              <br>
              <em>NeurIPS</em>, 2021
              <br>
              <p></p>
              <p>We study the uncertainty calibration and its relationship with accuracy of recent state-of-the-art image classification models.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
				<img src='images/vit.png' width=100%>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2010.11929">
                <papertitle>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</papertitle>
              </a>
              <br>
              Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, <strong>Matthias Minderer</strong>, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby
              <br>
              <em>ICLR</em>, 2021
              <br>
              <p></p>
              <p>We show that a pure transformer, applied directly to sequences of image patches, can perform very well on image classification tasks.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
				<img src='images/shortcuts.png' width=100%>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2002.08822">
                <papertitle>Automatic Shortcut Removal for Self-Supervised Representation Learning</papertitle>
              </a>
              <br>
              <strong>Matthias Minderer</strong>, Olivier Bachem, Neil Houlsby, Michael Tschannen
              <br>
              <em>ICML</em>, 2020
              <br>
              <p></p>
              <p>We tackle the problem of low-level shortcuts in self-supervised learning by training an adversarial "lens" to remove shortcut features from images.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
				<img src='images/unsupervised_object_structure.png' width=100%>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1906.07889">
                <papertitle>Unsupervised Learning of Object Structure and Dynamics from Videos</papertitle>
              </a>
              <br>
              <strong>Matthias Minderer</strong>, Chen Sun, Ruben Villegas, Kevin Murphy, Honglak Lee
              <br>
              <em>NeurIPS</em>, 2019
              <br>
              <p></p>
              <p>By using a spatially structured (keypoint-based) image representation, we improve video prediction quality and the usefulness of the learned video representations.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
				<img src='images/cortical_maps.png' width=100%>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/Minderer2019.pdf", target="_blank">
                <papertitle>The Spatial Structure of Neural Encoding in Mouse Posterior Cortex during Navigation</papertitle>
              </a>
              <br>
              <strong>Matthias Minderer</strong>, Kristen Brown, Christopher Harvey
              <br>
              <em>Neuron</em>, 2019
              <br>
              <p></p>
              <p>Using large-scale neural recordings and deep models of neural encoding, we show that navigation-related information is distributed and varies gradually across large parts of the posterior cortex, even across retinotopic boundaries.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
				<img src='images/driscoll2017.jpg' width=100%>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/driscoll2017.pdf", target="_blank">
                <papertitle>Dynamic Reorganization of Neuronal Activity Patterns in Parietal Cortex</papertitle>
              </a>
              <br>
              Laura Driscoll, Noah Pettit, <strong>Matthias Minderer</strong>, Selmaan Chettih, Christopher Harvey
              <br>
              <em>Cell</em>, 2017
              <br>
              <p></p>
              <p>Contrary to the idea that representations of sensory stimuli or the activity patterns that accompany motor actions are stable, neuronal representations in the parietal cortex can change across days, possibly allowing for the tradeoff between stable encoding of information and flexibility for incorporating new information.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
				<img src='images/vrSetupPerspective.png' width=100%>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/minderer2016.pdf", target="_blank">
                <papertitle>Neuroscience: Virtual reality explored</papertitle>
              </a>
              <br>
              <strong>Matthias Minderer</strong>, Christopher Harvey, Flavio Donato, Edvard Moser
              <br>
              <em>Nature</em>, 2016
              <br>
              <p></p>
              <p>We discuss the advantages of using virtual reality to study sensorimotor representations in the brain.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
				<img src='images/minderer2012.png' width=100%>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/Minderer2012.pdf", target="_blank">
                <papertitle>Chronic imaging of cortical sensory map dynamics using a genetically encoded calcium indicator</papertitle>
              </a>
              <br>
              <strong>Matthias Minderer</strong>, Wenrui Liu, Lazar Sumanovski, Sebastian K&uuml;gler, Fritjof Helmchen, David Margolis
              <br>
              <em>J Phys</em>, 2012
              <br>
              <p></p>
              <p>We present a method for fast fluorescence imaging of map-level cortical activity using a calcium indicator protein. Sensory-evoked neuronal activity can be imaged repeatedly in the same mouse over weeks, enabling new opportunities for the longitudinal study of cortical function and dysfunction.</p>
            </td>
          </tr>
    
		<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
		      <tbody><tr>
		        <td>
		        <br>
		        <p align="right"><font size="2">
		          Website design by <a href="https://people.eecs.berkeley.edu/~barron/">Jon Barron</a>.
		          </font>
		        </p>
		        </td>
		      </tr>
		      </tbody></table>
		      
		    </td>
		    </tr>
	  	</tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
